{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading split 'train' to '/home/andy/fiftyone/coco-2017/train' if necessary\n",
      "Downloading annotations to '/home/andy/fiftyone/coco-2017/tmp-download/annotations_trainval2017.zip'\n",
      "  15% |\\-----|  296.0Mb/1.9Gb [14.6s elapsed, 1.3m remaining, 37.0Mb/s]   \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/andy/Object_detection/FiftyOne.ipynb Cell 1\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=4'>5</a>\u001b[0m size \u001b[39m=\u001b[39m \u001b[39m200\u001b[39m\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m#sample_size = 100 # increase it to 2,000\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=7'>8</a>\u001b[0m dataset \u001b[39m=\u001b[39m foz\u001b[39m.\u001b[39;49mload_zoo_dataset(\n\u001b[1;32m      <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39m\"\u001b[39;49m\u001b[39mcoco-2017\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=9'>10</a>\u001b[0m     split \u001b[39m=\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=10'>11</a>\u001b[0m     label_types\u001b[39m=\u001b[39;49m[\u001b[39m\"\u001b[39;49m\u001b[39mdetections\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=11'>12</a>\u001b[0m     classes\u001b[39m=\u001b[39;49mclasses,\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=12'>13</a>\u001b[0m     only_matching \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,   \u001b[39m# only classes which we want\u001b[39;49;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=13'>14</a>\u001b[0m     max_samples \u001b[39m=\u001b[39;49m size\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu-20.04/home/andy/Object_detection/FiftyOne.ipynb#W0sdnNjb2RlLXJlbW90ZQ%3D%3D?line=14'>15</a>\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:197\u001b[0m, in \u001b[0;36mload_zoo_dataset\u001b[0;34m(name, split, splits, label_field, dataset_name, dataset_dir, download_if_necessary, drop_existing_dataset, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     zoo_dataset_cls \u001b[39m=\u001b[39m _get_zoo_dataset_cls(name)\n\u001b[1;32m    193\u001b[0m     download_kwargs, _ \u001b[39m=\u001b[39m fou\u001b[39m.\u001b[39mextract_kwargs_for_class(\n\u001b[1;32m    194\u001b[0m         zoo_dataset_cls, kwargs\n\u001b[1;32m    195\u001b[0m     )\n\u001b[0;32m--> 197\u001b[0m     info, dataset_dir \u001b[39m=\u001b[39m download_zoo_dataset(\n\u001b[1;32m    198\u001b[0m         name,\n\u001b[1;32m    199\u001b[0m         splits\u001b[39m=\u001b[39;49msplits,\n\u001b[1;32m    200\u001b[0m         dataset_dir\u001b[39m=\u001b[39;49mdataset_dir,\n\u001b[1;32m    201\u001b[0m         overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    202\u001b[0m         cleanup\u001b[39m=\u001b[39;49mcleanup,\n\u001b[1;32m    203\u001b[0m         \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mdownload_kwargs,\n\u001b[1;32m    204\u001b[0m     )\n\u001b[1;32m    205\u001b[0m     zoo_dataset \u001b[39m=\u001b[39m info\u001b[39m.\u001b[39mget_zoo_dataset()\n\u001b[1;32m    206\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:116\u001b[0m, in \u001b[0;36mdownload_zoo_dataset\u001b[0;34m(name, split, splits, dataset_dir, overwrite, cleanup, **kwargs)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[39m\"\"\"Downloads the dataset of the given name from the FiftyOne Dataset Zoo.\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \n\u001b[1;32m     83\u001b[0m \u001b[39mAny dataset splits that already exist in the specified directory are not\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[39m    -   dataset_dir: the directory containing the dataset\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    113\u001b[0m zoo_dataset, dataset_dir \u001b[39m=\u001b[39m _parse_dataset_details(\n\u001b[1;32m    114\u001b[0m     name, dataset_dir, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs\n\u001b[1;32m    115\u001b[0m )\n\u001b[0;32m--> 116\u001b[0m \u001b[39mreturn\u001b[39;00m zoo_dataset\u001b[39m.\u001b[39;49mdownload_and_prepare(\n\u001b[1;32m    117\u001b[0m     dataset_dir\u001b[39m=\u001b[39;49mdataset_dir,\n\u001b[1;32m    118\u001b[0m     split\u001b[39m=\u001b[39;49msplit,\n\u001b[1;32m    119\u001b[0m     splits\u001b[39m=\u001b[39;49msplits,\n\u001b[1;32m    120\u001b[0m     overwrite\u001b[39m=\u001b[39;49moverwrite,\n\u001b[1;32m    121\u001b[0m     cleanup\u001b[39m=\u001b[39;49mcleanup,\n\u001b[1;32m    122\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/__init__.py:1016\u001b[0m, in \u001b[0;36mZooDataset.download_and_prepare\u001b[0;34m(self, dataset_dir, split, splits, overwrite, cleanup)\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1005\u001b[0m     logger\u001b[39m.\u001b[39minfo(\n\u001b[1;32m   1006\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mDownloading split \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   1007\u001b[0m         split,\n\u001b[1;32m   1008\u001b[0m         split_dir,\n\u001b[1;32m   1009\u001b[0m         suffix,\n\u001b[1;32m   1010\u001b[0m     )\n\u001b[1;32m   1012\u001b[0m (\n\u001b[1;32m   1013\u001b[0m     dataset_type,\n\u001b[1;32m   1014\u001b[0m     num_samples,\n\u001b[1;32m   1015\u001b[0m     classes,\n\u001b[0;32m-> 1016\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_download_and_prepare(split_dir, scratch_dir, split)\n\u001b[1;32m   1018\u001b[0m \u001b[39m# Add split to ZooDatasetInfo\u001b[39;00m\n\u001b[1;32m   1019\u001b[0m \u001b[39mif\u001b[39;00m info \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/zoo/datasets/base.py:1146\u001b[0m, in \u001b[0;36mCOCO2017Dataset._download_and_prepare\u001b[0;34m(self, dataset_dir, scratch_dir, split)\u001b[0m\n\u001b[1;32m   1145\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_download_and_prepare\u001b[39m(\u001b[39mself\u001b[39m, dataset_dir, scratch_dir, split):\n\u001b[0;32m-> 1146\u001b[0m     num_samples, classes, downloaded \u001b[39m=\u001b[39m fouc\u001b[39m.\u001b[39;49mdownload_coco_dataset_split(\n\u001b[1;32m   1147\u001b[0m         dataset_dir,\n\u001b[1;32m   1148\u001b[0m         split,\n\u001b[1;32m   1149\u001b[0m         year\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m2017\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m   1150\u001b[0m         label_types\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlabel_types,\n\u001b[1;32m   1151\u001b[0m         classes\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclasses,\n\u001b[1;32m   1152\u001b[0m         image_ids\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mimage_ids,\n\u001b[1;32m   1153\u001b[0m         num_workers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_workers,\n\u001b[1;32m   1154\u001b[0m         shuffle\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshuffle,\n\u001b[1;32m   1155\u001b[0m         seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mseed,\n\u001b[1;32m   1156\u001b[0m         max_samples\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_samples,\n\u001b[1;32m   1157\u001b[0m         raw_dir\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_raw_dir(dataset_dir),\n\u001b[1;32m   1158\u001b[0m         scratch_dir\u001b[39m=\u001b[39;49mscratch_dir,\n\u001b[1;32m   1159\u001b[0m     )\n\u001b[1;32m   1161\u001b[0m     dataset_type \u001b[39m=\u001b[39m fot\u001b[39m.\u001b[39mCOCODetectionDataset()\n\u001b[1;32m   1163\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m downloaded:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/fiftyone/utils/coco.py:1480\u001b[0m, in \u001b[0;36mdownload_coco_dataset_split\u001b[0;34m(dataset_dir, split, year, label_types, classes, image_ids, num_workers, shuffle, seed, max_samples, raw_dir, scratch_dir)\u001b[0m\n\u001b[1;32m   1478\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(full_anno_path):\n\u001b[1;32m   1479\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mDownloading \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, anno_type, zip_path)\n\u001b[0;32m-> 1480\u001b[0m     etaw\u001b[39m.\u001b[39;49mdownload_file(src_path, path\u001b[39m=\u001b[39;49mzip_path)\n\u001b[1;32m   1482\u001b[0m     logger\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mExtracting \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m to \u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m, anno_type, full_anno_path)\n\u001b[1;32m   1483\u001b[0m     etau\u001b[39m.\u001b[39mextract_zip(zip_path, outdir\u001b[39m=\u001b[39munzip_dir, delete_zip\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:67\u001b[0m, in \u001b[0;36mdownload_file\u001b[0;34m(url, path, chunk_size, verify, quiet)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[39m\"\"\"Downloads a file from a URL. If a path is specified, the file is written\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[39mthere. Otherwise, the content is returned as a binary string.\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m    WebSessionError: if the download failed\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m sess \u001b[39m=\u001b[39m WebSession(chunk_size\u001b[39m=\u001b[39mchunk_size, verify\u001b[39m=\u001b[39mverify, quiet\u001b[39m=\u001b[39mquiet)\n\u001b[0;32m---> 67\u001b[0m \u001b[39mreturn\u001b[39;00m sess\u001b[39m.\u001b[39;49mwrite(path, url) \u001b[39mif\u001b[39;00m path \u001b[39melse\u001b[39;00m sess\u001b[39m.\u001b[39mget(url)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:150\u001b[0m, in \u001b[0;36mWebSession.write\u001b[0;34m(self, path, url, params)\u001b[0m\n\u001b[1;32m    148\u001b[0m etau\u001b[39m.\u001b[39mensure_basedir(path)\n\u001b[1;32m    149\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(path, \u001b[39m\"\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_do_download(r, f)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/eta/core/web.py:172\u001b[0m, in \u001b[0;36mWebSession._do_download\u001b[0;34m(self, r, f)\u001b[0m\n\u001b[1;32m    168\u001b[0m size_bits \u001b[39m=\u001b[39m \u001b[39m8\u001b[39m \u001b[39m*\u001b[39m size_bytes \u001b[39mif\u001b[39;00m size_bytes \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    169\u001b[0m \u001b[39mwith\u001b[39;00m etau\u001b[39m.\u001b[39mProgressBar(\n\u001b[1;32m    170\u001b[0m     size_bits, use_bits\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, quiet\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquiet\n\u001b[1;32m    171\u001b[0m ) \u001b[39mas\u001b[39;00m pb:\n\u001b[0;32m--> 172\u001b[0m     \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m r\u001b[39m.\u001b[39miter_content(chunk_size\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mchunk_size):\n\u001b[1;32m    173\u001b[0m         f\u001b[39m.\u001b[39mwrite(chunk)\n\u001b[1;32m    174\u001b[0m         pb\u001b[39m.\u001b[39mupdate(\u001b[39m8\u001b[39m \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(chunk))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/models.py:816\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    814\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mhasattr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw, \u001b[39m\"\u001b[39m\u001b[39mstream\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m    815\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 816\u001b[0m         \u001b[39myield from\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw\u001b[39m.\u001b[39mstream(chunk_size, decode_content\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    817\u001b[0m     \u001b[39mexcept\u001b[39;00m ProtocolError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    818\u001b[0m         \u001b[39mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:564\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    563\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mnot\u001b[39;00m is_fp_closed(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp):\n\u001b[0;32m--> 564\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(amt\u001b[39m=\u001b[39;49mamt, decode_content\u001b[39m=\u001b[39;49mdecode_content)\n\u001b[1;32m    566\u001b[0m         \u001b[39mif\u001b[39;00m data:\n\u001b[1;32m    567\u001b[0m             \u001b[39myield\u001b[39;00m data\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/response.py:507\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    506\u001b[0m     cache_content \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 507\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fp\u001b[39m.\u001b[39;49mread(amt) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m fp_closed \u001b[39melse\u001b[39;00m \u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    508\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    509\u001b[0m         amt \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m data\n\u001b[1;32m    510\u001b[0m     ):  \u001b[39m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    516\u001b[0m         \u001b[39m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[1;32m    517\u001b[0m         \u001b[39m# no harm in redundantly calling close.\u001b[39;00m\n\u001b[1;32m    518\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fp\u001b[39m.\u001b[39mclose()\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:459\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    456\u001b[0m \u001b[39mif\u001b[39;00m amt \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    457\u001b[0m     \u001b[39m# Amount is given, implement using readinto\u001b[39;00m\n\u001b[1;32m    458\u001b[0m     b \u001b[39m=\u001b[39m \u001b[39mbytearray\u001b[39m(amt)\n\u001b[0;32m--> 459\u001b[0m     n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    460\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mmemoryview\u001b[39m(b)[:n]\u001b[39m.\u001b[39mtobytes()\n\u001b[1;32m    461\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     \u001b[39m# Amount is not given (unbounded read) so we must check self.length\u001b[39;00m\n\u001b[1;32m    463\u001b[0m     \u001b[39m# and self.chunked\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3.8/http/client.py:503\u001b[0m, in \u001b[0;36mHTTPResponse.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    498\u001b[0m         b \u001b[39m=\u001b[39m \u001b[39mmemoryview\u001b[39m(b)[\u001b[39m0\u001b[39m:\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlength]\n\u001b[1;32m    500\u001b[0m \u001b[39m# we do not use _safe_read() here because this may be a .will_close\u001b[39;00m\n\u001b[1;32m    501\u001b[0m \u001b[39m# connection, and the user is reading more bytes than will be provided\u001b[39;00m\n\u001b[1;32m    502\u001b[0m \u001b[39m# (for example, reading in 1k chunks)\u001b[39;00m\n\u001b[0;32m--> 503\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadinto(b)\n\u001b[1;32m    504\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m n \u001b[39mand\u001b[39;00m b:\n\u001b[1;32m    505\u001b[0m     \u001b[39m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[1;32m    506\u001b[0m     \u001b[39m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n\u001b[1;32m    507\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_close_conn()\n",
      "File \u001b[0;32m/usr/lib/python3.8/socket.py:669\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    667\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    668\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 669\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    670\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    671\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n",
    "classes = [\"cow\"]\n",
    "size = 200\n",
    "#sample_size = 100 # increase it to 2,000\n",
    "\n",
    "dataset = foz.load_zoo_dataset(\n",
    "    \"coco-2017\",\n",
    "    split = \"train\",\n",
    "    label_types=[\"detections\"],\n",
    "    classes=classes,\n",
    "    only_matching = True,   # only classes which we want\n",
    "    max_samples = size\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        coco-2017-train-200\n",
      "Media type:  image\n",
      "Num samples: 200\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory 'c:\\Users\\andy.kim\\lecture_ws\\python_ws\\Object detection' already exists; export will be merged with existing files\n",
      " 100% |█████████████████| 200/200 [2.4s elapsed, 0s remaining, 85.5 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# data/, images.txt, obj.names\n",
    "dataset.export(\n",
    "    dataset_type=fo.types.YOLOv4Dataset,\n",
    "    #dataset_type=fo.types.COCODetectionDataset,\n",
    "    export_dir=os.getcwd(),  # save in 'data'\n",
    "    classes = classes\n",
    ")\n",
    "dataset.delete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def gen_images_txt(path):\n",
    "    #os.chdir(path)\n",
    "    file_names = os.listdir(path)\n",
    "    #file_len = len(file_names)\n",
    "\n",
    "    #print(file_names)\n",
    "    fout = open(\"images.txt\", \"w\") \n",
    "\n",
    "    #fout.write(\"test\\n\")\n",
    "    cnt = 0\n",
    "    for fname in file_names:\n",
    "        if \".jpg\" in fname:\n",
    "            fout.write(path+fname+'\\n')\n",
    "            cnt += 1\n",
    "\n",
    "    fout.close()\n",
    "    print('# of files', cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of files 200\n"
     ]
    }
   ],
   "source": [
    "file_path = 'data/'\n",
    "\n",
    "gen_images_txt(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from dir\n",
    "import fiftyone as fo\n",
    "import fiftyone.zoo as foz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100% |█████████████████| 200/200 [369.7ms elapsed, 0s remaining, 543.6 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "#dataset = foz.load_zoo_dataset(\"fashion-mnist\", split=\"test\")\n",
    "\n",
    "dataset_dir = \".\"\n",
    "\n",
    "# The type of the dataset being imported\n",
    "dataset_type = fo.types.YOLOv4Dataset  # for example\n",
    "\n",
    "# Import the dataset\n",
    "dataset = fo.Dataset.from_dir(\n",
    "    dataset_dir=dataset_dir,\n",
    "    dataset_type=dataset_type,\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        2022.12.03.23.49.51\n",
      "Media type:  image\n",
      "Num samples: 200\n",
      "Persistent:  False\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    id:           fiftyone.core.fields.ObjectIdField\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.ImageMetadata)\n",
      "    ground_truth: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"800\"\n",
       "            src=\"http://localhost:5151/?context=ipython&subscription=40a085ef-5056-48be-a1aa-d0729aadf1f4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7efcf6fb4c70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "session = fo.launch_app(dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10 (default, Jun 22 2022, 20:18:18) \n[GCC 9.4.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
